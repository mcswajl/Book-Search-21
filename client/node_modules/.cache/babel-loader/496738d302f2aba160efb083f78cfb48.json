{"ast":null,"code":"import { Source, isSource } from '../language/source.mjs';\nimport { TokenKind } from '../language/tokenKind.mjs';\nimport { Lexer, isPunctuatorTokenKind } from '../language/lexer.mjs';\nimport { printBlockString } from '../language/blockString.mjs';\n/**\r\n * Strips characters that are not significant to the validity or execution\r\n * of a GraphQL document:\r\n *   - UnicodeBOM\r\n *   - WhiteSpace\r\n *   - LineTerminator\r\n *   - Comment\r\n *   - Comma\r\n *   - BlockString indentation\r\n *\r\n * Note: It is required to have a delimiter character between neighboring\r\n * non-punctuator tokens and this function always uses single space as delimiter.\r\n *\r\n * It is guaranteed that both input and output documents if parsed would result\r\n * in the exact same AST except for nodes location.\r\n *\r\n * Warning: It is guaranteed that this function will always produce stable results.\r\n * However, it's not guaranteed that it will stay the same between different\r\n * releases due to bugfixes or changes in the GraphQL specification.\r\n *\r\n * Query example:\r\n *\r\n * ```graphql\r\n * query SomeQuery($foo: String!, $bar: String) {\r\n *   someField(foo: $foo, bar: $bar) {\r\n *     a\r\n *     b {\r\n *       c\r\n *       d\r\n *     }\r\n *   }\r\n * }\r\n * ```\r\n *\r\n * Becomes:\r\n *\r\n * ```graphql\r\n * query SomeQuery($foo:String!$bar:String){someField(foo:$foo bar:$bar){a b{c d}}}\r\n * ```\r\n *\r\n * SDL example:\r\n *\r\n * ```graphql\r\n * \"\"\"\r\n * Type description\r\n * \"\"\"\r\n * type Foo {\r\n *   \"\"\"\r\n *   Field description\r\n *   \"\"\"\r\n *   bar: String\r\n * }\r\n * ```\r\n *\r\n * Becomes:\r\n *\r\n * ```graphql\r\n * \"\"\"Type description\"\"\" type Foo{\"\"\"Field description\"\"\" bar:String}\r\n * ```\r\n */\n\nexport function stripIgnoredCharacters(source) {\n  const sourceObj = isSource(source) ? source : new Source(source);\n  const body = sourceObj.body;\n  const lexer = new Lexer(sourceObj);\n  let strippedBody = '';\n  let wasLastAddedTokenNonPunctuator = false;\n\n  while (lexer.advance().kind !== TokenKind.EOF) {\n    const currentToken = lexer.token;\n    const tokenKind = currentToken.kind;\n    /**\r\n     * Every two non-punctuator tokens should have space between them.\r\n     * Also prevent case of non-punctuator token following by spread resulting\r\n     * in invalid token (e.g. `1...` is invalid Float token).\r\n     */\n\n    const isNonPunctuator = !isPunctuatorTokenKind(currentToken.kind);\n\n    if (wasLastAddedTokenNonPunctuator) {\n      if (isNonPunctuator || currentToken.kind === TokenKind.SPREAD) {\n        strippedBody += ' ';\n      }\n    }\n\n    const tokenBody = body.slice(currentToken.start, currentToken.end);\n\n    if (tokenKind === TokenKind.BLOCK_STRING) {\n      strippedBody += printBlockString(currentToken.value, {\n        minimize: true\n      });\n    } else {\n      strippedBody += tokenBody;\n    }\n\n    wasLastAddedTokenNonPunctuator = isNonPunctuator;\n  }\n\n  return strippedBody;\n}","map":{"version":3,"sources":["C:/BootCamp/Book-Search-21/node_modules/graphql/utilities/stripIgnoredCharacters.mjs"],"names":["Source","isSource","TokenKind","Lexer","isPunctuatorTokenKind","printBlockString","stripIgnoredCharacters","source","sourceObj","body","lexer","strippedBody","wasLastAddedTokenNonPunctuator","advance","kind","EOF","currentToken","token","tokenKind","isNonPunctuator","SPREAD","tokenBody","slice","start","end","BLOCK_STRING","value","minimize"],"mappings":"AAAA,SAASA,MAAT,EAAiBC,QAAjB,QAAiC,wBAAjC;AACA,SAASC,SAAT,QAA0B,2BAA1B;AACA,SAASC,KAAT,EAAgBC,qBAAhB,QAA6C,uBAA7C;AACA,SAASC,gBAAT,QAAiC,6BAAjC;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6DA,OAAO,SAASC,sBAAT,CAAgCC,MAAhC,EAAwC;AAC7C,QAAMC,SAAS,GAAGP,QAAQ,CAACM,MAAD,CAAR,GAAmBA,MAAnB,GAA4B,IAAIP,MAAJ,CAAWO,MAAX,CAA9C;AACA,QAAME,IAAI,GAAGD,SAAS,CAACC,IAAvB;AACA,QAAMC,KAAK,GAAG,IAAIP,KAAJ,CAAUK,SAAV,CAAd;AACA,MAAIG,YAAY,GAAG,EAAnB;AACA,MAAIC,8BAA8B,GAAG,KAArC;;AAEA,SAAOF,KAAK,CAACG,OAAN,GAAgBC,IAAhB,KAAyBZ,SAAS,CAACa,GAA1C,EAA+C;AAC7C,UAAMC,YAAY,GAAGN,KAAK,CAACO,KAA3B;AACA,UAAMC,SAAS,GAAGF,YAAY,CAACF,IAA/B;AACA;;;;;;AAMA,UAAMK,eAAe,GAAG,CAACf,qBAAqB,CAACY,YAAY,CAACF,IAAd,CAA9C;;AAEA,QAAIF,8BAAJ,EAAoC;AAClC,UAAIO,eAAe,IAAIH,YAAY,CAACF,IAAb,KAAsBZ,SAAS,CAACkB,MAAvD,EAA+D;AAC7DT,QAAAA,YAAY,IAAI,GAAhB;AACD;AACF;;AAED,UAAMU,SAAS,GAAGZ,IAAI,CAACa,KAAL,CAAWN,YAAY,CAACO,KAAxB,EAA+BP,YAAY,CAACQ,GAA5C,CAAlB;;AAEA,QAAIN,SAAS,KAAKhB,SAAS,CAACuB,YAA5B,EAA0C;AACxCd,MAAAA,YAAY,IAAIN,gBAAgB,CAACW,YAAY,CAACU,KAAd,EAAqB;AACnDC,QAAAA,QAAQ,EAAE;AADyC,OAArB,CAAhC;AAGD,KAJD,MAIO;AACLhB,MAAAA,YAAY,IAAIU,SAAhB;AACD;;AAEDT,IAAAA,8BAA8B,GAAGO,eAAjC;AACD;;AAED,SAAOR,YAAP;AACD","sourcesContent":["import { Source, isSource } from '../language/source.mjs';\r\nimport { TokenKind } from '../language/tokenKind.mjs';\r\nimport { Lexer, isPunctuatorTokenKind } from '../language/lexer.mjs';\r\nimport { printBlockString } from '../language/blockString.mjs';\r\n/**\r\n * Strips characters that are not significant to the validity or execution\r\n * of a GraphQL document:\r\n *   - UnicodeBOM\r\n *   - WhiteSpace\r\n *   - LineTerminator\r\n *   - Comment\r\n *   - Comma\r\n *   - BlockString indentation\r\n *\r\n * Note: It is required to have a delimiter character between neighboring\r\n * non-punctuator tokens and this function always uses single space as delimiter.\r\n *\r\n * It is guaranteed that both input and output documents if parsed would result\r\n * in the exact same AST except for nodes location.\r\n *\r\n * Warning: It is guaranteed that this function will always produce stable results.\r\n * However, it's not guaranteed that it will stay the same between different\r\n * releases due to bugfixes or changes in the GraphQL specification.\r\n *\r\n * Query example:\r\n *\r\n * ```graphql\r\n * query SomeQuery($foo: String!, $bar: String) {\r\n *   someField(foo: $foo, bar: $bar) {\r\n *     a\r\n *     b {\r\n *       c\r\n *       d\r\n *     }\r\n *   }\r\n * }\r\n * ```\r\n *\r\n * Becomes:\r\n *\r\n * ```graphql\r\n * query SomeQuery($foo:String!$bar:String){someField(foo:$foo bar:$bar){a b{c d}}}\r\n * ```\r\n *\r\n * SDL example:\r\n *\r\n * ```graphql\r\n * \"\"\"\r\n * Type description\r\n * \"\"\"\r\n * type Foo {\r\n *   \"\"\"\r\n *   Field description\r\n *   \"\"\"\r\n *   bar: String\r\n * }\r\n * ```\r\n *\r\n * Becomes:\r\n *\r\n * ```graphql\r\n * \"\"\"Type description\"\"\" type Foo{\"\"\"Field description\"\"\" bar:String}\r\n * ```\r\n */\r\n\r\nexport function stripIgnoredCharacters(source) {\r\n  const sourceObj = isSource(source) ? source : new Source(source);\r\n  const body = sourceObj.body;\r\n  const lexer = new Lexer(sourceObj);\r\n  let strippedBody = '';\r\n  let wasLastAddedTokenNonPunctuator = false;\r\n\r\n  while (lexer.advance().kind !== TokenKind.EOF) {\r\n    const currentToken = lexer.token;\r\n    const tokenKind = currentToken.kind;\r\n    /**\r\n     * Every two non-punctuator tokens should have space between them.\r\n     * Also prevent case of non-punctuator token following by spread resulting\r\n     * in invalid token (e.g. `1...` is invalid Float token).\r\n     */\r\n\r\n    const isNonPunctuator = !isPunctuatorTokenKind(currentToken.kind);\r\n\r\n    if (wasLastAddedTokenNonPunctuator) {\r\n      if (isNonPunctuator || currentToken.kind === TokenKind.SPREAD) {\r\n        strippedBody += ' ';\r\n      }\r\n    }\r\n\r\n    const tokenBody = body.slice(currentToken.start, currentToken.end);\r\n\r\n    if (tokenKind === TokenKind.BLOCK_STRING) {\r\n      strippedBody += printBlockString(currentToken.value, {\r\n        minimize: true,\r\n      });\r\n    } else {\r\n      strippedBody += tokenBody;\r\n    }\r\n\r\n    wasLastAddedTokenNonPunctuator = isNonPunctuator;\r\n  }\r\n\r\n  return strippedBody;\r\n}\r\n"]},"metadata":{},"sourceType":"module"}